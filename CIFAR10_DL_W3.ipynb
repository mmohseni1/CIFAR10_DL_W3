{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "colab": {
      "name": "CNN_assignment1_2019.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Df3tIR0ORy61"
      },
      "source": [
        "Upload the cifar10 from the keras.datasets. The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, \n",
        "with 6000 images per class. There are 50000 training images and 10000 test images. \n",
        "\n",
        "for more information about the dataset please see: https://www.cs.toronto.edu/~kriz/cifar.html\n",
        "\n",
        "Split data to the train and test.\n",
        "Convert the class label to binary class label"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZWlk1VpRy6-"
      },
      "source": [
        "import keras\n",
        "import tensorflow as tf\n",
        "from keras.utils import np_utils\n",
        "from keras.models import Sequential\n",
        "from keras.metrics import categorical_crossentropy\n",
        "from keras.layers.core import Dense,Dropout,Activation,Flatten\n",
        "from keras.layers.convolutional import Convolution2D,MaxPooling2D"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oEqK0c3kjpcb",
        "outputId": "7acf24f8-2105-4069-89fd-d32e4edf34c0"
      },
      "source": [
        "# Loading the CIFAR-10 datasets\n",
        "from keras.datasets import cifar10\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data() \n",
        "print(\"x_train shape:\", x_train.shape)\n",
        "print(x_train.shape[0], \"train samples\")\n",
        "print(x_test.shape[0], \"test samples\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y9oEJs3NRy7A"
      },
      "source": [
        "Normalized the data and train the model using CNN."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7hs5OfhpmS_c",
        "outputId": "f4d87c14-8e1f-467c-d94f-6cf3f6a5e2de"
      },
      "source": [
        "print(y_train.shape)\n",
        "y_train = np_utils.to_categorical(y_train, 10)\n",
        "y_train.shape\n",
        "y_test = np_utils.to_categorical(y_test, 10)\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train  /= 255\n",
        "x_test /= 255"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gUpSVfjDmTY6",
        "outputId": "e50d68dd-78b4-42d9-e954-d11f60f57370"
      },
      "source": [
        "# here we can replace x_train.shape[1:] by (32,32,3)\n",
        "model=Sequential()\n",
        "model.add(Convolution2D(32,(3,3),input_shape=x_train.shape[1:])) \n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(Convolution2D(64,(3,3)))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "# Dense layer is one dimentional data set while convolution is 2 dimentional dataset\n",
        "model.add(Flatten())\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(256))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(Dense(10))\n",
        "model.add(Activation(tf.nn.softmax)) \n",
        "model.summary()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 30, 30, 32)        896       \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 30, 30, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 13, 13, 64)        18496     \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 13, 13, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               590080    \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                2570      \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 612,042\n",
            "Trainable params: 612,042\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wW1EOsHmpjr"
      },
      "source": [
        "model.compile(optimizer=\"adam\",loss='categorical_crossentropy',metrics=[\"accuracy\"])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "in_sO2iFRy7A",
        "outputId": "aef8ba0d-e4e6-4f89-d4c1-eecac7846dda"
      },
      "source": [
        "model.fit(x=x_train,y=y_train,batch_size=1,epochs=10,validation_data=(x_test,y_test))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "50000/50000 [==============================] - 284s 6ms/step - loss: 1.6465 - accuracy: 0.4008 - val_loss: 1.2907 - val_accuracy: 0.5483\n",
            "Epoch 2/10\n",
            "50000/50000 [==============================] - 265s 5ms/step - loss: 1.2937 - accuracy: 0.5470 - val_loss: 1.3431 - val_accuracy: 0.5441\n",
            "Epoch 3/10\n",
            "50000/50000 [==============================] - 275s 5ms/step - loss: 1.2247 - accuracy: 0.5777 - val_loss: 1.1970 - val_accuracy: 0.5912\n",
            "Epoch 4/10\n",
            "50000/50000 [==============================] - 273s 5ms/step - loss: 1.1805 - accuracy: 0.5921 - val_loss: 1.3269 - val_accuracy: 0.5638\n",
            "Epoch 5/10\n",
            "50000/50000 [==============================] - 273s 5ms/step - loss: 1.1573 - accuracy: 0.6035 - val_loss: 1.2195 - val_accuracy: 0.5918\n",
            "Epoch 6/10\n",
            "50000/50000 [==============================] - 272s 5ms/step - loss: 1.1570 - accuracy: 0.6043 - val_loss: 1.1729 - val_accuracy: 0.5997\n",
            "Epoch 7/10\n",
            "50000/50000 [==============================] - 271s 5ms/step - loss: 1.1448 - accuracy: 0.6159 - val_loss: 1.2575 - val_accuracy: 0.5686\n",
            "Epoch 8/10\n",
            "50000/50000 [==============================] - 274s 5ms/step - loss: 1.1565 - accuracy: 0.6093 - val_loss: 1.3405 - val_accuracy: 0.5757\n",
            "Epoch 9/10\n",
            "50000/50000 [==============================] - 262s 5ms/step - loss: 1.1545 - accuracy: 0.6109 - val_loss: 1.2724 - val_accuracy: 0.5746\n",
            "Epoch 10/10\n",
            "50000/50000 [==============================] - 260s 5ms/step - loss: 1.1542 - accuracy: 0.6110 - val_loss: 1.3978 - val_accuracy: 0.5638\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f0ec88bc0f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zV5isyARRy7B"
      },
      "source": [
        "Evaluate the accuracy of the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16ZxdjV0Ry7B",
        "outputId": "3aaa0bae-6d5a-4996-e8dd-8f556d9a79ae"
      },
      "source": [
        "results = model.evaluate(x_test, y_test, verbose=0, batch_size=1)\n",
        "print(\"Test loss, Test accuracy:\", results)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss, Test accuracy: [1.3977798223495483, 0.5637999773025513]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}